\relax 
\citation{netflixprize}
\newlabel{^_1}{{}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{netflixprize}
\citation{kagglecompetitions}
\citation{kaggleguide}
\citation{classifiercomparison}
\citation{classifiercomparison}
\citation{Simpson13}
\citation{UCIrep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.1}}Datasets}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Our collection of 10 datasets from the UCI repository. Columns represent the number of instances, number of variables and the percentage of the majority class for each of the datasets after missing data is removed. Further detail on each dataset can be found in the list following the table.}}{2}}
\newlabel{table:datasets}{{1}{2}}
\citation{Simpson13}
\citation{Simpson13}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.2}}Data Conversion \& Processing}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.3}}Base Classifiers}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.4}}Ensembling Process}{3}}
\newlabel{ensemblingprocess}{{{2.4}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.5}}Ensemble Classifiers}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.6}}Comparison Metric}{3}}
\citation{netflixprize}
\citation{kagglecompetitions}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results \& Discussion}{4}}
\newlabel{results&discussion}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Base Classifier Accuracy on a Variety of Datasets}}{5}}
\newlabel{fig:01}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Ensemble Classifier Accuracy on a Variety of Datasets}}{6}}
\newlabel{fig:02}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Non-Meta-Learning Ensemble Accuracy on Small (pale colours) vs Large (dark colours) training sets}}{7}}
\newlabel{fig:03}{{3}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces AUC scores for base classifiers on each dataset. \newline  * see Section 3\hbox {}.}}{8}}
\newlabel{fig:04}{{2}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces AUC scores for ensemble classifiers \& best base classifier on each dataset.}}{8}}
\newlabel{fig:05}{{3}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces AUC scores for non-meta-learning ensemble classifiers with small and large base classifier training set on each dataset.}}{9}}
\newlabel{fig:06}{{4}{9}}
\bibcite{Simpson13}{{1}{}{{}}{{}}}
\bibcite{UCIrep}{{2}{}{{}}{{}}}
\bibcite{classifiercomparison}{{3}{}{{}}{{}}}
\bibcite{glmnet}{{4}{}{{}}{{}}}
\bibcite{randomforest}{{5}{}{{}}{{}}}
\bibcite{gbm}{{6}{}{{}}{{}}}
\bibcite{kernlab}{{7}{}{{}}{{}}}
\bibcite{neuralnet}{{8}{}{{}}{{}}}
\bibcite{c50}{{9}{}{{}}{{}}}
\bibcite{caret}{{10}{}{{}}{{}}}
\bibcite{klar}{{11}{}{{}}{{}}}
\bibcite{mass}{{12}{}{{}}{{}}}
\bibcite{netflixprize}{{13}{}{{}}{{}}}
\bibcite{kagglecompetitions}{{14}{}{{}}{{}}}
\bibcite{kaggleguide}{{15}{}{{}}{{}}}
\global\@namedef{@lastpage@}{10}
\global\NAT@numberstrue
